[
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "librosa",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "librosa",
        "description": "librosa",
        "detail": "librosa",
        "documentation": {}
    },
    {
        "label": "soundfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "soundfile",
        "description": "soundfile",
        "detail": "soundfile",
        "documentation": {}
    },
    {
        "label": "TextNormalizer",
        "importPath": "avatar_ui.TTS_pipeline.text_preprocess",
        "description": "avatar_ui.TTS_pipeline.text_preprocess",
        "isExtraImport": true,
        "detail": "avatar_ui.TTS_pipeline.text_preprocess",
        "documentation": {}
    },
    {
        "label": "G2PConverter",
        "importPath": "avatar_ui.TTS_pipeline.hybrid_G2P",
        "description": "avatar_ui.TTS_pipeline.hybrid_G2P",
        "isExtraImport": true,
        "detail": "avatar_ui.TTS_pipeline.hybrid_G2P",
        "documentation": {}
    },
    {
        "label": "pad_sequences",
        "importPath": "tensorflow.keras.preprocessing.sequence",
        "description": "tensorflow.keras.preprocessing.sequence",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing.sequence",
        "documentation": {}
    },
    {
        "label": "layers",
        "importPath": "tensorflow.keras",
        "description": "tensorflow.keras",
        "isExtraImport": true,
        "detail": "tensorflow.keras",
        "documentation": {}
    },
    {
        "label": "register_keras_serializable",
        "importPath": "keras.saving",
        "description": "keras.saving",
        "isExtraImport": true,
        "detail": "keras.saving",
        "documentation": {}
    },
    {
        "label": "enable_unsafe_deserialization",
        "importPath": "keras.config",
        "description": "keras.config",
        "isExtraImport": true,
        "detail": "keras.config",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "ast",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ast",
        "description": "ast",
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "cmudict",
        "importPath": "nltk.corpus",
        "description": "nltk.corpus",
        "isExtraImport": true,
        "detail": "nltk.corpus",
        "documentation": {}
    },
    {
        "label": "cmudict",
        "importPath": "nltk.corpus",
        "description": "nltk.corpus",
        "isExtraImport": true,
        "detail": "nltk.corpus",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "unicodedata",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unicodedata",
        "description": "unicodedata",
        "detail": "unicodedata",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "contractions",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "contractions",
        "description": "contractions",
        "detail": "contractions",
        "documentation": {}
    },
    {
        "label": "num2words",
        "importPath": "num2words",
        "description": "num2words",
        "isExtraImport": true,
        "detail": "num2words",
        "documentation": {}
    },
    {
        "label": "js",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "js",
        "description": "js",
        "detail": "js",
        "documentation": {}
    },
    {
        "label": "asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio",
        "description": "asyncio",
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "render_template",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "send_from_directory",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "url_for",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "redirect",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "render_template",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "send_from_directory",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "url_for",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "redirect",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "send_file",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Response",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "secure_filename",
        "importPath": "werkzeug.utils",
        "description": "werkzeug.utils",
        "isExtraImport": true,
        "detail": "werkzeug.utils",
        "documentation": {}
    },
    {
        "label": "secure_filename",
        "importPath": "werkzeug.utils",
        "description": "werkzeug.utils",
        "isExtraImport": true,
        "detail": "werkzeug.utils",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "TTS_inference",
        "importPath": "avatar_ui.TTS_pipeline",
        "description": "avatar_ui.TTS_pipeline",
        "isExtraImport": true,
        "detail": "avatar_ui.TTS_pipeline",
        "documentation": {}
    },
    {
        "label": "gTTS",
        "importPath": "gtts",
        "description": "gtts",
        "isExtraImport": true,
        "detail": "gtts",
        "documentation": {}
    },
    {
        "label": "chromadb",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "chromadb",
        "description": "chromadb",
        "detail": "chromadb",
        "documentation": {}
    },
    {
        "label": "Chroma",
        "importPath": "langchain_community.vectorstores",
        "description": "langchain_community.vectorstores",
        "isExtraImport": true,
        "detail": "langchain_community.vectorstores",
        "documentation": {}
    },
    {
        "label": "HuggingFaceEmbeddings",
        "importPath": "langchain_community.embeddings",
        "description": "langchain_community.embeddings",
        "isExtraImport": true,
        "detail": "langchain_community.embeddings",
        "documentation": {}
    },
    {
        "label": "Llama",
        "importPath": "llama_cpp",
        "description": "llama_cpp",
        "isExtraImport": true,
        "detail": "llama_cpp",
        "documentation": {}
    },
    {
        "label": "Settings",
        "importPath": "chromadb.config",
        "description": "chromadb.config",
        "isExtraImport": true,
        "detail": "chromadb.config",
        "documentation": {}
    },
    {
        "label": "CropLayer",
        "kind": 6,
        "importPath": "avatar_ui.TTS_pipeline.TTS_inference",
        "description": "avatar_ui.TTS_pipeline.TTS_inference",
        "peekOfCode": "class CropLayer(tf.keras.layers.Layer):\n    def __init__(self, length, **kwargs):\n        super().__init__(**kwargs)\n        self.length = length\n    def call(self, inputs):\n        return inputs[:, :self.length, :]\n    def get_config(self):\n        config = super().get_config()\n        config.update({'length': self.length})\n        return config",
        "detail": "avatar_ui.TTS_pipeline.TTS_inference",
        "documentation": {}
    },
    {
        "label": "AdditiveAttention",
        "kind": 6,
        "importPath": "avatar_ui.TTS_pipeline.TTS_inference",
        "description": "avatar_ui.TTS_pipeline.TTS_inference",
        "peekOfCode": "class AdditiveAttention(tf.keras.layers.Layer):\n    def __init__(self, units, **kwargs):\n        super(AdditiveAttention, self).__init__(**kwargs)\n        self.W_query = tf.keras.layers.Dense(units)\n        self.W_values = tf.keras.layers.Dense(units)\n        self.V = tf.keras.layers.Dense(1)\n    def call(self, query, values, mask=None):\n        query = tf.expand_dims(query, 1)\n        score = self.V(tf.nn.tanh(self.W_query(query) + self.W_values(values)))\n        score = tf.squeeze(score, axis=-1)",
        "detail": "avatar_ui.TTS_pipeline.TTS_inference",
        "documentation": {}
    },
    {
        "label": "AttentionContextLayer",
        "kind": 6,
        "importPath": "avatar_ui.TTS_pipeline.TTS_inference",
        "description": "avatar_ui.TTS_pipeline.TTS_inference",
        "peekOfCode": "class AttentionContextLayer(tf.keras.layers.Layer):\n    def __init__(self, units, input_length, **kwargs):\n        super(AttentionContextLayer, self).__init__(**kwargs)\n        self.units = units\n        self.input_length = input_length\n    def build(self, input_shape):\n        self.attention = AdditiveAttention(units=self.units)\n        super(AttentionContextLayer, self).build(input_shape)\n    def call(self, inputs):\n        query, values, mask = inputs",
        "detail": "avatar_ui.TTS_pipeline.TTS_inference",
        "documentation": {}
    },
    {
        "label": "LocationSensitiveAttention",
        "kind": 6,
        "importPath": "avatar_ui.TTS_pipeline.TTS_inference",
        "description": "avatar_ui.TTS_pipeline.TTS_inference",
        "peekOfCode": "class LocationSensitiveAttention(tf.keras.layers.Layer):\n    def __init__(self, units, filters=32, kernel_size=31, **kwargs):\n        super(LocationSensitiveAttention, self).__init__(**kwargs)\n        self.units = units\n        self.filters = filters\n        self.kernel_size = kernel_size\n        self.W_query = layers.Dense(units)\n        self.W_values = layers.Dense(units)\n        self.W_location = layers.Dense(units)\n        self.V = layers.Dense(1)",
        "detail": "avatar_ui.TTS_pipeline.TTS_inference",
        "documentation": {}
    },
    {
        "label": "LocationAttentionContextLayer",
        "kind": 6,
        "importPath": "avatar_ui.TTS_pipeline.TTS_inference",
        "description": "avatar_ui.TTS_pipeline.TTS_inference",
        "peekOfCode": "class LocationAttentionContextLayer(tf.keras.layers.Layer):\n    def __init__(self, units, input_length, **kwargs):\n        super(LocationAttentionContextLayer, self).__init__(**kwargs)\n        self.units = units\n        self.input_length = input_length\n    def build(self, input_shape):\n        self.attention = LocationSensitiveAttention(units=self.units)\n        super().build(input_shape)\n    def call(self, inputs):\n        query, values, prev_attention, mask = inputs",
        "detail": "avatar_ui.TTS_pipeline.TTS_inference",
        "documentation": {}
    },
    {
        "label": "PositionalEncoding",
        "kind": 6,
        "importPath": "avatar_ui.TTS_pipeline.TTS_inference",
        "description": "avatar_ui.TTS_pipeline.TTS_inference",
        "peekOfCode": "class PositionalEncoding(tf.keras.layers.Layer):\n    def __init__(self, input_length, embed_dim, **kwargs):\n        super(PositionalEncoding, self).__init__(**kwargs)\n        self.pos_embedding = tf.keras.layers.Embedding(input_dim=input_length, output_dim=embed_dim)\n    def call(self, x):\n        seq_len = tf.shape(x)[1]\n        positions = tf.range(start=0, limit=seq_len, delta=1)\n        positions = tf.expand_dims(positions, 0)\n        pos_encoded = self.pos_embedding(positions)\n        return pos_encoded",
        "detail": "avatar_ui.TTS_pipeline.TTS_inference",
        "documentation": {}
    },
    {
        "label": "LastTimestep",
        "kind": 6,
        "importPath": "avatar_ui.TTS_pipeline.TTS_inference",
        "description": "avatar_ui.TTS_pipeline.TTS_inference",
        "peekOfCode": "class LastTimestep(tf.keras.layers.Layer):\n    def call(self, inputs):\n        return inputs[:, -1, :]\nclass CustomTTS:\n    def __init__(self):\n        self.best_model = None\n        self.g2p = None\n        self.normalizer = None\n        self.mel_mean = None\n        self.mel_std = None",
        "detail": "avatar_ui.TTS_pipeline.TTS_inference",
        "documentation": {}
    },
    {
        "label": "CustomTTS",
        "kind": 6,
        "importPath": "avatar_ui.TTS_pipeline.TTS_inference",
        "description": "avatar_ui.TTS_pipeline.TTS_inference",
        "peekOfCode": "class CustomTTS:\n    def __init__(self):\n        self.best_model = None\n        self.g2p = None\n        self.normalizer = None\n        self.mel_mean = None\n        self.mel_std = None\n        self.is_loaded = False\n        self._load_models()\n    def _load_models(self):",
        "detail": "avatar_ui.TTS_pipeline.TTS_inference",
        "documentation": {}
    },
    {
        "label": "start",
        "kind": 5,
        "importPath": "avatar_ui.TTS_pipeline.TTS_inference",
        "description": "avatar_ui.TTS_pipeline.TTS_inference",
        "peekOfCode": "start = datetime.datetime.now()\nimport io\nimport os\nimport tensorflow as tf\nimport numpy as np\nimport librosa\nimport soundfile as sf\nfrom avatar_ui.TTS_pipeline.text_preprocess import TextNormalizer\nfrom avatar_ui.TTS_pipeline.hybrid_G2P import G2PConverter\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences",
        "detail": "avatar_ui.TTS_pipeline.TTS_inference",
        "documentation": {}
    },
    {
        "label": "tts_model_instance",
        "kind": 5,
        "importPath": "avatar_ui.TTS_pipeline.TTS_inference",
        "description": "avatar_ui.TTS_pipeline.TTS_inference",
        "peekOfCode": "tts_model_instance = CustomTTS()\n# tts_model_instance.synthesize(text=text)\nif not tts_model_instance.is_loaded:\n    print(\"TTS: WARNING: CustomTTS model failed to load during initialization.\")",
        "detail": "avatar_ui.TTS_pipeline.TTS_inference",
        "documentation": {}
    },
    {
        "label": "G2PConverter",
        "kind": 6,
        "importPath": "avatar_ui.TTS_pipeline.hybrid_G2P",
        "description": "avatar_ui.TTS_pipeline.hybrid_G2P",
        "peekOfCode": "class G2PConverter:\n    def __init__(self, model_path=None, vocab_path=\"avatar_ui/TTS_pipeline/data/cmu_dict_with_stress.csv\", max_len=33, load_model=True):\n        self.max_len = max_len\n        self.phoneme_dict=cmudict.dict()\n        if load_model and model_path:\n            self.model = tf.keras.models.load_model(model_path)\n        self._load_vocab(vocab_path)\n    def _load_vocab(self, vocab_path):\n        df = pd.read_csv(vocab_path)        \n        self.words = df[\"word\"].tolist()",
        "detail": "avatar_ui.TTS_pipeline.hybrid_G2P",
        "documentation": {}
    },
    {
        "label": "TextNormalizer",
        "kind": 6,
        "importPath": "avatar_ui.TTS_pipeline.text_preprocess",
        "description": "avatar_ui.TTS_pipeline.text_preprocess",
        "peekOfCode": "class TextNormalizer:\n    def __init__(self):\n        self.abbreviations = [(re.compile('\\\\b%s\\\\.' % x[0], re.IGNORECASE), x[1]) for x in [\n                ('mrs', 'misess'),\n                ('mr', 'mister'),\n                ('dr', 'doctor'),\n                ('drs', 'doctors'),\n                ('st', 'saint'),\n                ('co', 'company'),\n                ('jr', 'junior'),",
        "detail": "avatar_ui.TTS_pipeline.text_preprocess",
        "documentation": {}
    },
    {
        "label": "_pad",
        "kind": 5,
        "importPath": "avatar_ui.TTS_pipeline.text_preprocess",
        "description": "avatar_ui.TTS_pipeline.text_preprocess",
        "peekOfCode": "_pad = \"_\"\n_punctuation = \"!'(),.:;? \"\n_special = \"-\"\n_silences = [\"@sp\", \"@spn\", \"@sil\"]\nclass TextNormalizer:\n    def __init__(self):\n        self.abbreviations = [(re.compile('\\\\b%s\\\\.' % x[0], re.IGNORECASE), x[1]) for x in [\n                ('mrs', 'misess'),\n                ('mr', 'mister'),\n                ('dr', 'doctor'),",
        "detail": "avatar_ui.TTS_pipeline.text_preprocess",
        "documentation": {}
    },
    {
        "label": "_punctuation",
        "kind": 5,
        "importPath": "avatar_ui.TTS_pipeline.text_preprocess",
        "description": "avatar_ui.TTS_pipeline.text_preprocess",
        "peekOfCode": "_punctuation = \"!'(),.:;? \"\n_special = \"-\"\n_silences = [\"@sp\", \"@spn\", \"@sil\"]\nclass TextNormalizer:\n    def __init__(self):\n        self.abbreviations = [(re.compile('\\\\b%s\\\\.' % x[0], re.IGNORECASE), x[1]) for x in [\n                ('mrs', 'misess'),\n                ('mr', 'mister'),\n                ('dr', 'doctor'),\n                ('drs', 'doctors'),",
        "detail": "avatar_ui.TTS_pipeline.text_preprocess",
        "documentation": {}
    },
    {
        "label": "_special",
        "kind": 5,
        "importPath": "avatar_ui.TTS_pipeline.text_preprocess",
        "description": "avatar_ui.TTS_pipeline.text_preprocess",
        "peekOfCode": "_special = \"-\"\n_silences = [\"@sp\", \"@spn\", \"@sil\"]\nclass TextNormalizer:\n    def __init__(self):\n        self.abbreviations = [(re.compile('\\\\b%s\\\\.' % x[0], re.IGNORECASE), x[1]) for x in [\n                ('mrs', 'misess'),\n                ('mr', 'mister'),\n                ('dr', 'doctor'),\n                ('drs', 'doctors'),\n                ('st', 'saint'),",
        "detail": "avatar_ui.TTS_pipeline.text_preprocess",
        "documentation": {}
    },
    {
        "label": "_silences",
        "kind": 5,
        "importPath": "avatar_ui.TTS_pipeline.text_preprocess",
        "description": "avatar_ui.TTS_pipeline.text_preprocess",
        "peekOfCode": "_silences = [\"@sp\", \"@spn\", \"@sil\"]\nclass TextNormalizer:\n    def __init__(self):\n        self.abbreviations = [(re.compile('\\\\b%s\\\\.' % x[0], re.IGNORECASE), x[1]) for x in [\n                ('mrs', 'misess'),\n                ('mr', 'mister'),\n                ('dr', 'doctor'),\n                ('drs', 'doctors'),\n                ('st', 'saint'),\n                ('co', 'company'),",
        "detail": "avatar_ui.TTS_pipeline.text_preprocess",
        "documentation": {}
    },
    {
        "label": "update_info",
        "kind": 2,
        "importPath": "avatar_ui.static.py.main",
        "description": "avatar_ui.static.py.main",
        "peekOfCode": "def update_info(message):\n    \"\"\"Helper function to update the info div in HTML.\"\"\"\n    info_div = js.document.getElementById('info')\n    if info_div:\n        info_div.textContent = message\n    else:\n        print(f\"Python Warning: Could not find #info div. Message: {message}\")\nasync def handle_mic_click(event=None):\n    \"\"\"\n    Handles the mic button click event to start/stop speech recognition.",
        "detail": "avatar_ui.static.py.main",
        "documentation": {}
    },
    {
        "label": "play_audio",
        "kind": 2,
        "importPath": "avatar_ui.static.py.main",
        "description": "avatar_ui.static.py.main",
        "peekOfCode": "def play_audio(audio_file_path, event=None):\n    global current_audio\n    if current_audio is not None:\n        current_audio.pause()\n        current_audio.currentTime = 0 \n    audio = js.Audio.new(audio_file_path)\n    audio.play()\n    current_audio = audio \nasync def py_sendMessage(event=None):\n    \"\"\"",
        "detail": "avatar_ui.static.py.main",
        "documentation": {}
    },
    {
        "label": "speech_recognition_active",
        "kind": 5,
        "importPath": "avatar_ui.static.py.main",
        "description": "avatar_ui.static.py.main",
        "peekOfCode": "speech_recognition_active = False\ncurrent_py_utterance = None\ndef update_info(message):\n    \"\"\"Helper function to update the info div in HTML.\"\"\"\n    info_div = js.document.getElementById('info')\n    if info_div:\n        info_div.textContent = message\n    else:\n        print(f\"Python Warning: Could not find #info div. Message: {message}\")\nasync def handle_mic_click(event=None):",
        "detail": "avatar_ui.static.py.main",
        "documentation": {}
    },
    {
        "label": "current_py_utterance",
        "kind": 5,
        "importPath": "avatar_ui.static.py.main",
        "description": "avatar_ui.static.py.main",
        "peekOfCode": "current_py_utterance = None\ndef update_info(message):\n    \"\"\"Helper function to update the info div in HTML.\"\"\"\n    info_div = js.document.getElementById('info')\n    if info_div:\n        info_div.textContent = message\n    else:\n        print(f\"Python Warning: Could not find #info div. Message: {message}\")\nasync def handle_mic_click(event=None):\n    \"\"\"",
        "detail": "avatar_ui.static.py.main",
        "documentation": {}
    },
    {
        "label": "current_audio",
        "kind": 5,
        "importPath": "avatar_ui.static.py.main",
        "description": "avatar_ui.static.py.main",
        "peekOfCode": "current_audio = None\ndef play_audio(audio_file_path, event=None):\n    global current_audio\n    if current_audio is not None:\n        current_audio.pause()\n        current_audio.currentTime = 0 \n    audio = js.Audio.new(audio_file_path)\n    audio.play()\n    current_audio = audio \nasync def py_sendMessage(event=None):",
        "detail": "avatar_ui.static.py.main",
        "documentation": {}
    },
    {
        "label": "index",
        "kind": 2,
        "importPath": "avatar_ui.app",
        "description": "avatar_ui.app",
        "peekOfCode": "def index():\n    return render_template('index.html', avatars=avatars)\nSTATIC_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'static')\napp.config['STATIC_FOLDER'] = STATIC_FOLDER\n@app.route('/static/models/<path:filename>')\ndef serve_model(filename):\n    print(f\"Serving model file: {filename}\")\n    return send_from_directory(os.path.join(STATIC_FOLDER, 'models'), filename)\n@app.route('/upload', methods=['POST'])\ndef upload():",
        "detail": "avatar_ui.app",
        "documentation": {}
    },
    {
        "label": "serve_model",
        "kind": 2,
        "importPath": "avatar_ui.app",
        "description": "avatar_ui.app",
        "peekOfCode": "def serve_model(filename):\n    print(f\"Serving model file: {filename}\")\n    return send_from_directory(os.path.join(STATIC_FOLDER, 'models'), filename)\n@app.route('/upload', methods=['POST'])\ndef upload():\n    image = request.files['image']\n    avatar_name = request.form['avatar_name']\n    if image:\n        filename = secure_filename(image.filename)\n        image.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))",
        "detail": "avatar_ui.app",
        "documentation": {}
    },
    {
        "label": "upload",
        "kind": 2,
        "importPath": "avatar_ui.app",
        "description": "avatar_ui.app",
        "peekOfCode": "def upload():\n    image = request.files['image']\n    avatar_name = request.form['avatar_name']\n    if image:\n        filename = secure_filename(image.filename)\n        image.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n        avatar_url = url_for('static', filename=f'uploads/{filename}')\n        avatars.append({'name': avatar_name, 'url': avatar_url})\n    return redirect(url_for('index'))\nif __name__ == '__main__':",
        "detail": "avatar_ui.app",
        "documentation": {}
    },
    {
        "label": "index",
        "kind": 2,
        "importPath": "avatar_ui.app",
        "description": "avatar_ui.app",
        "peekOfCode": "def index():\n    return render_template('index.html', uploaded_image=None)\n@app.route('/upload', methods=['POST'])\ndef upload():\n    if 'image' not in request.files:\n        return \"No file part\", 400\n    img = request.files['image']\n    print(img)\n    if img.filename == '':\n        return \"No selected file\", 400",
        "detail": "avatar_ui.app",
        "documentation": {}
    },
    {
        "label": "upload",
        "kind": 2,
        "importPath": "avatar_ui.app",
        "description": "avatar_ui.app",
        "peekOfCode": "def upload():\n    if 'image' not in request.files:\n        return \"No file part\", 400\n    img = request.files['image']\n    print(img)\n    if img.filename == '':\n        return \"No selected file\", 400\n    img_path = os.path.join(app.config['UPLOAD_FOLDER'], img.filename)\n    try:\n        img.save(img_path)",
        "detail": "avatar_ui.app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "avatar_ui.app",
        "description": "avatar_ui.app",
        "peekOfCode": "app = Flask(__name__)\nUPLOAD_FOLDER = 'avatar_ui/static/uploads'\nos.makedirs(UPLOAD_FOLDER, exist_ok=True)\napp.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n# Get all uploaded avatars and their names\navatars = []\n@app.route('/')\ndef index():\n    return render_template('index.html', avatars=avatars)\nSTATIC_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'static')",
        "detail": "avatar_ui.app",
        "documentation": {}
    },
    {
        "label": "UPLOAD_FOLDER",
        "kind": 5,
        "importPath": "avatar_ui.app",
        "description": "avatar_ui.app",
        "peekOfCode": "UPLOAD_FOLDER = 'avatar_ui/static/uploads'\nos.makedirs(UPLOAD_FOLDER, exist_ok=True)\napp.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n# Get all uploaded avatars and their names\navatars = []\n@app.route('/')\ndef index():\n    return render_template('index.html', avatars=avatars)\nSTATIC_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'static')\napp.config['STATIC_FOLDER'] = STATIC_FOLDER",
        "detail": "avatar_ui.app",
        "documentation": {}
    },
    {
        "label": "app.config['UPLOAD_FOLDER']",
        "kind": 5,
        "importPath": "avatar_ui.app",
        "description": "avatar_ui.app",
        "peekOfCode": "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n# Get all uploaded avatars and their names\navatars = []\n@app.route('/')\ndef index():\n    return render_template('index.html', avatars=avatars)\nSTATIC_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'static')\napp.config['STATIC_FOLDER'] = STATIC_FOLDER\n@app.route('/static/models/<path:filename>')\ndef serve_model(filename):",
        "detail": "avatar_ui.app",
        "documentation": {}
    },
    {
        "label": "avatars",
        "kind": 5,
        "importPath": "avatar_ui.app",
        "description": "avatar_ui.app",
        "peekOfCode": "avatars = []\n@app.route('/')\ndef index():\n    return render_template('index.html', avatars=avatars)\nSTATIC_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'static')\napp.config['STATIC_FOLDER'] = STATIC_FOLDER\n@app.route('/static/models/<path:filename>')\ndef serve_model(filename):\n    print(f\"Serving model file: {filename}\")\n    return send_from_directory(os.path.join(STATIC_FOLDER, 'models'), filename)",
        "detail": "avatar_ui.app",
        "documentation": {}
    },
    {
        "label": "STATIC_FOLDER",
        "kind": 5,
        "importPath": "avatar_ui.app",
        "description": "avatar_ui.app",
        "peekOfCode": "STATIC_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'static')\napp.config['STATIC_FOLDER'] = STATIC_FOLDER\n@app.route('/static/models/<path:filename>')\ndef serve_model(filename):\n    print(f\"Serving model file: {filename}\")\n    return send_from_directory(os.path.join(STATIC_FOLDER, 'models'), filename)\n@app.route('/upload', methods=['POST'])\ndef upload():\n    image = request.files['image']\n    avatar_name = request.form['avatar_name']",
        "detail": "avatar_ui.app",
        "documentation": {}
    },
    {
        "label": "app.config['STATIC_FOLDER']",
        "kind": 5,
        "importPath": "avatar_ui.app",
        "description": "avatar_ui.app",
        "peekOfCode": "app.config['STATIC_FOLDER'] = STATIC_FOLDER\n@app.route('/static/models/<path:filename>')\ndef serve_model(filename):\n    print(f\"Serving model file: {filename}\")\n    return send_from_directory(os.path.join(STATIC_FOLDER, 'models'), filename)\n@app.route('/upload', methods=['POST'])\ndef upload():\n    image = request.files['image']\n    avatar_name = request.form['avatar_name']\n    if image:",
        "detail": "avatar_ui.app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "avatar_ui.app",
        "description": "avatar_ui.app",
        "peekOfCode": "app = Flask(__name__)\nUPLOAD_FOLDER = 'avatar_ui/static/uploads'\nos.makedirs(UPLOAD_FOLDER, exist_ok=True)\napp.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n@app.route('/')\ndef index():\n    return render_template('index.html', uploaded_image=None)\n@app.route('/upload', methods=['POST'])\ndef upload():\n    if 'image' not in request.files:",
        "detail": "avatar_ui.app",
        "documentation": {}
    },
    {
        "label": "UPLOAD_FOLDER",
        "kind": 5,
        "importPath": "avatar_ui.app",
        "description": "avatar_ui.app",
        "peekOfCode": "UPLOAD_FOLDER = 'avatar_ui/static/uploads'\nos.makedirs(UPLOAD_FOLDER, exist_ok=True)\napp.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n@app.route('/')\ndef index():\n    return render_template('index.html', uploaded_image=None)\n@app.route('/upload', methods=['POST'])\ndef upload():\n    if 'image' not in request.files:\n        return \"No file part\", 400",
        "detail": "avatar_ui.app",
        "documentation": {}
    },
    {
        "label": "app.config['UPLOAD_FOLDER']",
        "kind": 5,
        "importPath": "avatar_ui.app",
        "description": "avatar_ui.app",
        "peekOfCode": "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n@app.route('/')\ndef index():\n    return render_template('index.html', uploaded_image=None)\n@app.route('/upload', methods=['POST'])\ndef upload():\n    if 'image' not in request.files:\n        return \"No file part\", 400\n    img = request.files['image']\n    print(img)",
        "detail": "avatar_ui.app",
        "documentation": {}
    },
    {
        "label": "index",
        "kind": 2,
        "importPath": "avatar_ui.app_render3d",
        "description": "avatar_ui.app_render3d",
        "peekOfCode": "def index():\n    return render_template('index1.html',avatars=avatars)\nSTATIC_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'static')\napp.config['STATIC_FOLDER'] = STATIC_FOLDER\nos.makedirs(os.path.join(STATIC_FOLDER, 'models'), exist_ok=True)\napp.config['MODEL_FOLDER'] = os.path.join(STATIC_FOLDER, 'models')\n# This route serves ANY file from the static/models subdirectory, including .glb\n@app.route('/static/models/<path:filename>')\ndef serve_model(filename):\n    print(f\"Serving model file: {filename}\")",
        "detail": "avatar_ui.app_render3d",
        "documentation": {}
    },
    {
        "label": "serve_model",
        "kind": 2,
        "importPath": "avatar_ui.app_render3d",
        "description": "avatar_ui.app_render3d",
        "peekOfCode": "def serve_model(filename):\n    print(f\"Serving model file: {filename}\")\n    return send_from_directory(os.path.join(STATIC_FOLDER, 'models'), filename)\n@app.route('/upload', methods=['POST'])\ndef upload():\n    image = request.files['image']\n    avatar_name = request.form['avatar_name']\n    if image:\n        filename = secure_filename(image.filename)\n        image.save(os.path.join(app.config['MODEL_FOLDER'], filename))",
        "detail": "avatar_ui.app_render3d",
        "documentation": {}
    },
    {
        "label": "upload",
        "kind": 2,
        "importPath": "avatar_ui.app_render3d",
        "description": "avatar_ui.app_render3d",
        "peekOfCode": "def upload():\n    image = request.files['image']\n    avatar_name = request.form['avatar_name']\n    if image:\n        filename = secure_filename(image.filename)\n        image.save(os.path.join(app.config['MODEL_FOLDER'], filename))\n        avatar_url = url_for('static', filename=f'models/{filename}')\n        avatars.append({'name': avatar_name, 'url': avatar_url})\n    return redirect(url_for('index'))\ncustom=True",
        "detail": "avatar_ui.app_render3d",
        "documentation": {}
    },
    {
        "label": "synthesize_speech",
        "kind": 2,
        "importPath": "avatar_ui.app_render3d",
        "description": "avatar_ui.app_render3d",
        "peekOfCode": "def synthesize_speech():\n    try:\n        data = request.get_json(silent=True)\n        print(\"Flask: Received json for TTS:\",data)\n        if data is None:\n            print(\"Flask Request: Body is not valid JSON or is empty.\")\n            return jsonify({\"error\": \"Invalid JSON or empty body provided\"}), 400\n        text = data.get('text')\n        if not text:\n            print(\"Flask Request: 'text' field missing from JSON payload.\")",
        "detail": "avatar_ui.app_render3d",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "avatar_ui.app_render3d",
        "description": "avatar_ui.app_render3d",
        "peekOfCode": "app = Flask(__name__)\nUPLOAD_FOLDER = 'avatar_ui/static/uploads'\nos.makedirs(UPLOAD_FOLDER, exist_ok=True)\napp.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n# Get all uploaded avatars and their names\navatars = []    \n@app.route('/')\ndef index():\n    return render_template('index1.html',avatars=avatars)\nSTATIC_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'static')",
        "detail": "avatar_ui.app_render3d",
        "documentation": {}
    },
    {
        "label": "UPLOAD_FOLDER",
        "kind": 5,
        "importPath": "avatar_ui.app_render3d",
        "description": "avatar_ui.app_render3d",
        "peekOfCode": "UPLOAD_FOLDER = 'avatar_ui/static/uploads'\nos.makedirs(UPLOAD_FOLDER, exist_ok=True)\napp.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n# Get all uploaded avatars and their names\navatars = []    \n@app.route('/')\ndef index():\n    return render_template('index1.html',avatars=avatars)\nSTATIC_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'static')\napp.config['STATIC_FOLDER'] = STATIC_FOLDER",
        "detail": "avatar_ui.app_render3d",
        "documentation": {}
    },
    {
        "label": "app.config['UPLOAD_FOLDER']",
        "kind": 5,
        "importPath": "avatar_ui.app_render3d",
        "description": "avatar_ui.app_render3d",
        "peekOfCode": "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n# Get all uploaded avatars and their names\navatars = []    \n@app.route('/')\ndef index():\n    return render_template('index1.html',avatars=avatars)\nSTATIC_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'static')\napp.config['STATIC_FOLDER'] = STATIC_FOLDER\nos.makedirs(os.path.join(STATIC_FOLDER, 'models'), exist_ok=True)\napp.config['MODEL_FOLDER'] = os.path.join(STATIC_FOLDER, 'models')",
        "detail": "avatar_ui.app_render3d",
        "documentation": {}
    },
    {
        "label": "avatars",
        "kind": 5,
        "importPath": "avatar_ui.app_render3d",
        "description": "avatar_ui.app_render3d",
        "peekOfCode": "avatars = []    \n@app.route('/')\ndef index():\n    return render_template('index1.html',avatars=avatars)\nSTATIC_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'static')\napp.config['STATIC_FOLDER'] = STATIC_FOLDER\nos.makedirs(os.path.join(STATIC_FOLDER, 'models'), exist_ok=True)\napp.config['MODEL_FOLDER'] = os.path.join(STATIC_FOLDER, 'models')\n# This route serves ANY file from the static/models subdirectory, including .glb\n@app.route('/static/models/<path:filename>')",
        "detail": "avatar_ui.app_render3d",
        "documentation": {}
    },
    {
        "label": "STATIC_FOLDER",
        "kind": 5,
        "importPath": "avatar_ui.app_render3d",
        "description": "avatar_ui.app_render3d",
        "peekOfCode": "STATIC_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'static')\napp.config['STATIC_FOLDER'] = STATIC_FOLDER\nos.makedirs(os.path.join(STATIC_FOLDER, 'models'), exist_ok=True)\napp.config['MODEL_FOLDER'] = os.path.join(STATIC_FOLDER, 'models')\n# This route serves ANY file from the static/models subdirectory, including .glb\n@app.route('/static/models/<path:filename>')\ndef serve_model(filename):\n    print(f\"Serving model file: {filename}\")\n    return send_from_directory(os.path.join(STATIC_FOLDER, 'models'), filename)\n@app.route('/upload', methods=['POST'])",
        "detail": "avatar_ui.app_render3d",
        "documentation": {}
    },
    {
        "label": "app.config['STATIC_FOLDER']",
        "kind": 5,
        "importPath": "avatar_ui.app_render3d",
        "description": "avatar_ui.app_render3d",
        "peekOfCode": "app.config['STATIC_FOLDER'] = STATIC_FOLDER\nos.makedirs(os.path.join(STATIC_FOLDER, 'models'), exist_ok=True)\napp.config['MODEL_FOLDER'] = os.path.join(STATIC_FOLDER, 'models')\n# This route serves ANY file from the static/models subdirectory, including .glb\n@app.route('/static/models/<path:filename>')\ndef serve_model(filename):\n    print(f\"Serving model file: {filename}\")\n    return send_from_directory(os.path.join(STATIC_FOLDER, 'models'), filename)\n@app.route('/upload', methods=['POST'])\ndef upload():",
        "detail": "avatar_ui.app_render3d",
        "documentation": {}
    },
    {
        "label": "app.config['MODEL_FOLDER']",
        "kind": 5,
        "importPath": "avatar_ui.app_render3d",
        "description": "avatar_ui.app_render3d",
        "peekOfCode": "app.config['MODEL_FOLDER'] = os.path.join(STATIC_FOLDER, 'models')\n# This route serves ANY file from the static/models subdirectory, including .glb\n@app.route('/static/models/<path:filename>')\ndef serve_model(filename):\n    print(f\"Serving model file: {filename}\")\n    return send_from_directory(os.path.join(STATIC_FOLDER, 'models'), filename)\n@app.route('/upload', methods=['POST'])\ndef upload():\n    image = request.files['image']\n    avatar_name = request.form['avatar_name']",
        "detail": "avatar_ui.app_render3d",
        "documentation": {}
    },
    {
        "label": "retrieve_response",
        "kind": 2,
        "importPath": "avatar_ui.rag",
        "description": "avatar_ui.rag",
        "peekOfCode": "def retrieve_response(query):\n    docs = vector_store.similarity_search(query, k=1)\n    # print(\"\\n🟢 Retrieved document:\", docs[0].metadata[\"answer\"] if docs else \"None\")\n    return docs[0].metadata[\"answer\"] if docs else \"Sorry, I don't know the answer.\"\n# Load LLaMA model\nllm = Llama(model_path=\"avatar_ui/models/mistral-7b-instruct-v0.1.Q2_K.gguf\",\n            verbose=False)\n# RAG logic\ndef rag_chatbot(query):\n    retrieved_text = retrieve_response(query)",
        "detail": "avatar_ui.rag",
        "documentation": {}
    },
    {
        "label": "rag_chatbot",
        "kind": 2,
        "importPath": "avatar_ui.rag",
        "description": "avatar_ui.rag",
        "peekOfCode": "def rag_chatbot(query):\n    retrieved_text = retrieve_response(query)\n    prompt = (\n        f\"User asked: {query}\\n\\n\"\n        f\"Relevant Info: {retrieved_text}\\n\\n\"\n        f\"Answer: concisely based only on the relevant info above:\"\n    )\n    print(\"\\n🟡 Prompt sent to LLaMA:\\n\", prompt)\n    response = llm(f\"[INST] {prompt} [/INST]\", max_tokens=100, temperature=0.7)\n    print(\"\\n🔵 LLaMA raw response:\\n\", response)",
        "detail": "avatar_ui.rag",
        "documentation": {}
    },
    {
        "label": "get_chat_response",
        "kind": 2,
        "importPath": "avatar_ui.rag",
        "description": "avatar_ui.rag",
        "peekOfCode": "def get_chat_response(prompt):\n    return rag_chatbot(prompt)",
        "detail": "avatar_ui.rag",
        "documentation": {}
    },
    {
        "label": "json_file_path",
        "kind": 5,
        "importPath": "avatar_ui.rag",
        "description": "avatar_ui.rag",
        "peekOfCode": "json_file_path = os.path.join(os.path.dirname(__file__), \"Expertise.json\")\nwith open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n    dataset = json.load(f)\nquestions = [item[\"question\"] for item in dataset]\nanswers = [item[\"answer\"] for item in dataset]\n# Initialize ChromaDB\nchroma_path = os.path.join(\"avatar_ui\", \"chroma_db\")\nchroma_client = chromadb.PersistentClient(path=chroma_path)\n# Load embeddings model\nembeddings = HuggingFaceEmbeddings(",
        "detail": "avatar_ui.rag",
        "documentation": {}
    },
    {
        "label": "questions",
        "kind": 5,
        "importPath": "avatar_ui.rag",
        "description": "avatar_ui.rag",
        "peekOfCode": "questions = [item[\"question\"] for item in dataset]\nanswers = [item[\"answer\"] for item in dataset]\n# Initialize ChromaDB\nchroma_path = os.path.join(\"avatar_ui\", \"chroma_db\")\nchroma_client = chromadb.PersistentClient(path=chroma_path)\n# Load embeddings model\nembeddings = HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n    encode_kwargs={\"batch_size\": 256}\n)",
        "detail": "avatar_ui.rag",
        "documentation": {}
    },
    {
        "label": "answers",
        "kind": 5,
        "importPath": "avatar_ui.rag",
        "description": "avatar_ui.rag",
        "peekOfCode": "answers = [item[\"answer\"] for item in dataset]\n# Initialize ChromaDB\nchroma_path = os.path.join(\"avatar_ui\", \"chroma_db\")\nchroma_client = chromadb.PersistentClient(path=chroma_path)\n# Load embeddings model\nembeddings = HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n    encode_kwargs={\"batch_size\": 256}\n)\n# Store data in ChromaDB",
        "detail": "avatar_ui.rag",
        "documentation": {}
    },
    {
        "label": "chroma_path",
        "kind": 5,
        "importPath": "avatar_ui.rag",
        "description": "avatar_ui.rag",
        "peekOfCode": "chroma_path = os.path.join(\"avatar_ui\", \"chroma_db\")\nchroma_client = chromadb.PersistentClient(path=chroma_path)\n# Load embeddings model\nembeddings = HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n    encode_kwargs={\"batch_size\": 256}\n)\n# Store data in ChromaDB\nvector_store = Chroma.from_texts(\n    texts=questions,",
        "detail": "avatar_ui.rag",
        "documentation": {}
    },
    {
        "label": "chroma_client",
        "kind": 5,
        "importPath": "avatar_ui.rag",
        "description": "avatar_ui.rag",
        "peekOfCode": "chroma_client = chromadb.PersistentClient(path=chroma_path)\n# Load embeddings model\nembeddings = HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n    encode_kwargs={\"batch_size\": 256}\n)\n# Store data in ChromaDB\nvector_store = Chroma.from_texts(\n    texts=questions,\n    metadatas=[{\"answer\": ans} for ans in answers],",
        "detail": "avatar_ui.rag",
        "documentation": {}
    },
    {
        "label": "embeddings",
        "kind": 5,
        "importPath": "avatar_ui.rag",
        "description": "avatar_ui.rag",
        "peekOfCode": "embeddings = HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n    encode_kwargs={\"batch_size\": 256}\n)\n# Store data in ChromaDB\nvector_store = Chroma.from_texts(\n    texts=questions,\n    metadatas=[{\"answer\": ans} for ans in answers],\n    embedding=embeddings,\n    persist_directory=chroma_path",
        "detail": "avatar_ui.rag",
        "documentation": {}
    },
    {
        "label": "vector_store",
        "kind": 5,
        "importPath": "avatar_ui.rag",
        "description": "avatar_ui.rag",
        "peekOfCode": "vector_store = Chroma.from_texts(\n    texts=questions,\n    metadatas=[{\"answer\": ans} for ans in answers],\n    embedding=embeddings,\n    persist_directory=chroma_path\n)\nprint(\"Dataset successfully stored in ChromaDB!\")\n# Function to retrieve response from ChromaDB\ndef retrieve_response(query):\n    docs = vector_store.similarity_search(query, k=1)",
        "detail": "avatar_ui.rag",
        "documentation": {}
    },
    {
        "label": "llm",
        "kind": 5,
        "importPath": "avatar_ui.rag",
        "description": "avatar_ui.rag",
        "peekOfCode": "llm = Llama(model_path=\"avatar_ui/models/mistral-7b-instruct-v0.1.Q2_K.gguf\",\n            verbose=False)\n# RAG logic\ndef rag_chatbot(query):\n    retrieved_text = retrieve_response(query)\n    prompt = (\n        f\"User asked: {query}\\n\\n\"\n        f\"Relevant Info: {retrieved_text}\\n\\n\"\n        f\"Answer: concisely based only on the relevant info above:\"\n    )",
        "detail": "avatar_ui.rag",
        "documentation": {}
    }
]